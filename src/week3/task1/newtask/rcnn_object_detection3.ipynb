{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T02:24:35.175247Z",
     "start_time": "2024-09-19T02:24:33.659579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torchvision\n",
    "from torchvision import  transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import week3.task1.newtask.pytorch_utils as pytorch_utils"
   ],
   "id": "58b6845ac2bb4265",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-19T02:29:21.945438Z",
     "start_time": "2024-09-19T02:28:03.115212Z"
    }
   },
   "source": [
    "def coord_calculator(x, y, w, h, ih, iw):\n",
    "        x1 = (x - (w / 2)) * iw\n",
    "        x2 = (x + (w / 2)) * iw\n",
    "        y1 = (y - (h / 2)) * ih\n",
    "        y2 = (y + (h / 2)) * ih\n",
    "        return round(x1), round(y1), round(x2), round(y2)\n",
    "\n",
    "fs = [# '/Users/ashleycui/data/coco2014/val2014/COCO_val2014_000000000042.jpg',\n",
    "        '/Users/ashleycui/data/coco2014/val2014/COCO_val2014_000000000136.jpg',\n",
    "      # '/Users/ashleycui/data/coco2014/val2014/COCO_val2014_000000001083.jpg',\n",
    "      # '/Users/ashleycui/data/coco2014/val2014/COCO_val2014_000000001374.jpg',\n",
    "      # '/Users/ashleycui/data/coco2014/val2014/COCO_val2014_000000001561.jpg'\n",
    "]\n",
    "\n",
    "half = 0.5\n",
    "duration = 0\n",
    "for i in fs:\n",
    "        # model\n",
    "        start = time.time()\n",
    "        model_ = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=True)\n",
    "        model_.eval()\n",
    "        for name, param in model_.named_parameters():\n",
    "                # freezing the part of the model as no changes happen to its parameters\n",
    "                param.requires_grad = False\n",
    "        def model(x):\n",
    "                with torch.no_grad():\n",
    "                        yhat = model_(x)\n",
    "                return yhat\n",
    "        end = time.time()\n",
    "        duration += (end - start)\n",
    "        print(duration)\n",
    "        \n",
    "        # getting image\n",
    "        img_path = i\n",
    "        image = Image.open(img_path)\n",
    "        image.resize([int(half * s) for s in image.size])\n",
    "        dims = image.size\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        img = transform(image)\n",
    "        \n",
    "        # getting pred\n",
    "        pred = model([img])\n",
    "        pred_thresh = pytorch_utils.get_predictions(pred, threshold=0.5)\n",
    "        # pytorch_utils.draw_box(pred_thresh, img, rect_th=1, text_size= 0.5, text_th=1)\n",
    "        img = (np.clip(cv2.cvtColor(np.clip(img.numpy().transpose((1, 2, 0)), 0, 1), cv2.COLOR_RGB2BGR), 0, 1) * 255).astype(np.uint8).copy()\n",
    "\n",
    "        total = correct = 0\n",
    "        # reading txt file \n",
    "        with open('/Users/ashleycui/data/txt/COCO_val2014_000000000136.txt','r') as f:\n",
    "                for line in f.readlines():\n",
    "                        segs = line.split()\n",
    "                        clz = int(segs[0]) + 1\n",
    "                        cx, cy = float(segs[1]), float(segs[2])\n",
    "                        w, h = float(segs[3]), float(segs[4])\n",
    "\n",
    "                        x1, y1, x2, y2 = coord_calculator(cx, cy, w, h, dims[1], dims[0])\n",
    "                        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "                        text_size= 0.3\n",
    "                        text_th=1\n",
    "                        \n",
    "                        maxiou = 0\n",
    "                        labelx = None\n",
    "                        \n",
    "                        for predicted_class in pred_thresh:\n",
    "                                label = predicted_class[0]\n",
    "                                probability = predicted_class[1]\n",
    "                                box = predicted_class[2]\n",
    "                                t = round(box[0][0].tolist())\n",
    "                                l = round(box[0][1].tolist())\n",
    "                                r = round(box[1][0].tolist())\n",
    "                                b = round(box[1][1].tolist())\n",
    "                                \n",
    "                                iou = pytorch_utils.get_iou({'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2}, {'x1':t, 'x2':r, 'y1':l, 'y2':b})\n",
    "                                print(f'iou: {iou}')\n",
    "                                maxiou = max(maxiou, iou)\n",
    "\n",
    "                                cv2.rectangle(img, (t, l), (r, b), (0, 255, 0), 1)\n",
    "                                cv2.rectangle(img, (t, l), (t+70, l+17), (255, 255, 255), -1)\n",
    "                                cv2.putText(img, label+\": \"+str(round(probability, 2)), (t+10, l+12),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                            text_size, (0,255,0), thickness=text_th)\n",
    "                                # cv2.putText(img, label+\": \"+str(round(probability, 2)),\n",
    "                                #             (x1+10, y1+12),  cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                                #             (0, 255, 0),thickness=text_th)\n",
    "                                if maxiou == iou:\n",
    "                                        labelx = label\n",
    "                                \n",
    "                        label2 = pytorch_utils.COCO_INSTANCE_CATEGORY_NAMES[clz]\n",
    "                        if label2 == labelx:\n",
    "                                correct += 1\n",
    "                        total += 1\n",
    "                        print(f'{total} {correct}')\n",
    "\n",
    "        img = np.array(img)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        # if download_image:\n",
    "        #     # plt.savefig(f'{img_name}.png')\n",
    "        # else:\n",
    "        #     pass\n",
    "        plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59775710105896\n",
      "iou: 0.0\n",
      "iou: 0.0\n",
      "iou: 0.6068328716528163\n",
      "iou: 0.6119916804131105\n",
      "1 0\n",
      "iou: 0.0\n",
      "iou: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 86\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[38;5;66;03m# cv2.putText(img, label+\": \"+str(round(probability, 2)),\u001B[39;00m\n\u001B[1;32m     83\u001B[0m         \u001B[38;5;66;03m#             (x1+10, y1+12),  cv2.FONT_HERSHEY_SIMPLEX, text_size,\u001B[39;00m\n\u001B[1;32m     84\u001B[0m         \u001B[38;5;66;03m#             (0, 255, 0),thickness=text_th)\u001B[39;00m\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m maxiou \u001B[38;5;241m==\u001B[39m iou:\n\u001B[0;32m---> 86\u001B[0m                 labelx \u001B[38;5;241m=\u001B[39m \u001B[43mlabel\u001B[49m\n\u001B[1;32m     88\u001B[0m label2 \u001B[38;5;241m=\u001B[39m pytorch_utils\u001B[38;5;241m.\u001B[39mCOCO_INSTANCE_CATEGORY_NAMES[clz]\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m label2 \u001B[38;5;241m==\u001B[39m labelx:\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/IDEA-U/ch-0/241.15989.150/IntelliJ IDEA.app.plugins/python/helpers/pydev/pydevd.py:1185\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1182\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1184\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1185\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/IDEA-U/ch-0/241.15989.150/IntelliJ IDEA.app.plugins/python/helpers/pydev/pydevd.py:1200\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1197\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1199\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1200\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
